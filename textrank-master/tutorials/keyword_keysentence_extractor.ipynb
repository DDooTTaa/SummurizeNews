{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KoNLPy 의 Komoran 을 이용하여 라라랜드 영화 리뷰를 토크나이징 한 텍스트를 `lalaland_komoran.txt` 에, 원문을 `lalaland.txt` 에 저장하였습니다. 총 15,595 건의 영화평입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15595 15595\n"
     ]
    }
   ],
   "source": [
    "# Komoran tokenized La La Land review\n",
    "with open('./lalaland_komoran.txt', encoding='utf-8') as f:\n",
    "    sents = [sent.strip() for sent in f]\n",
    "\n",
    "with open('./lalaland.txt', encoding='utf-8') as f:\n",
    "    texts = [sent.strip() for sent in f]\n",
    "\n",
    "print(len(sents), len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/wls40/Downloads/PyKoSpacing-master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextRank 에서는 word cooccurrence graph 를 만들 때 명사와 동사 등을 이용할 것을 제안하였습니다. 이는 조사나 관사와 같이 의미를 지니지 않으면서도 자주 이용되는 단어들이 높은 PageRank 를 가지게 되는 것을 방지하기 위해서입니다.\n",
    "\n",
    "Komoran 에서의 명사 (NN), 어근 (XR), 형용사 (VA), 동사 (VV) 만을 이용하여 word cooccurrence graph 를 만듭니다. window 를 -1 로 설정하면 한 문장에서 얼마나 떨어져 있던지 상관없이 cooccurrence 를 계산하며, window 가 1 보다 클 경우에는 해당 간격만큼만 떨어진 단어들 간에만 cooccurrence 를 인정합니다.\n",
    "\n",
    "학습 결과 `영화`, `음악`, `꿈`, `마지막` 같은 라라랜드의 엔딩을 의미하는 단어들이 핵심 단어로 선택되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "영화/NNG (1.73e+02)\n보/VV (1.29e+02)\n좋/VA (65.5)\n하/VV (52.0)\n것/NNB (47.4)\n같/VA (45.4)\n영화/NNP (43.8)\n음악/NNG (43.6)\n꿈/NNG (41.4)\n있/VV (40.8)\n없/VA (35.9)\n마지막/NNG (31.9)\n수/NNB (30.1)\n사랑/NNG (28.3)\n아름답/VA (26.5)\n현실/NNG (24.8)\n되/VV (23.9)\n노래/NNG (23.4)\n생각/NNG (23.2)\n스토리/NNP (21.4)\n번/NNB (20.3)\n거/NNB (19.7)\n최고/NNG (19.2)\n때/NNG (19.1)\n사람/NNG (19.0)\n여운/NNP (17.5)\n뮤지컬/NNP (16.9)\n나오/VV (16.5)\n듯/NNB (16.1)\n영상미/NNG (16.0)\n"
     ]
    }
   ],
   "source": [
    "from textrank import *\n",
    "\n",
    "def komoran_tokenize(sent):\n",
    "    words = sent.split()\n",
    "    words = [w for w in words if ('/NN' in w or '/XR' in w or '/VA' in w or '/VV' in w)]\n",
    "    return words\n",
    "\n",
    "keyword_extractor = KeywordSummarizer(\n",
    "    tokenize = komoran_tokenize,\n",
    "    window = -1,\n",
    "    verbose = False\n",
    ")\n",
    "keywords = keyword_extractor.summarize(sents, topk=30)\n",
    "for word, rank in keywords:\n",
    "    print('{} ({:.3})'.format(word, rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 모든 단어를 이용할 경우에는 조사 (JKG, JX, JKS, ... ) 어미 (EC, EP, ... ) 등이 핵심 단어로 선택됩니다. 이는 word cooccurrence graph 는 사실상 출현빈도가 높은 단어들이 높은 Rank 를 가지도록 유도하기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ㄴ/ETM (1.24e+02)\n고/EC (1.03e+02)\n영화/NNG (96.8)\n는/ETM (94.6)\n이/VCP (92.3)\n이/JKS (92.0)\n하/XSV (85.2)\n에/JKB (79.0)\n았/EP (76.1)\n보/VV (73.5)\n었/EP (72.8)\n다/EC (68.3)\n을/JKO (64.2)\n하/XSA (58.8)\n의/JKG (58.4)\n도/JX (52.7)\nㄹ/ETM (50.2)\n가/JKS (47.2)\n게/EC (46.7)\n는/JX (42.3)\n어/EC (37.9)\n좋/VA (37.6)\n를/JKO (34.3)\n아/EC (33.8)\n은/ETM (33.7)\n들/XSN (32.6)\n은/JX (32.0)\n하/VV (29.8)\n것/NNB (26.7)\n과/JC (26.5)\n"
     ]
    }
   ],
   "source": [
    "keyword_extractor = KeywordSummarizer(\n",
    "    tokenize=lambda x:x.split(),\n",
    "    verbose = False\n",
    ")\n",
    "keywords = keyword_extractor.summarize(sents, topk=30)\n",
    "for word, rank in keywords:\n",
    "    print('{} ({:.3})'.format(word, rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "window 의 크기를 바꾼다 하여도 큰 변화는 없습니다. 약간의 순위 변동은 있지만, 큰 맥락이 변하지는 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "영화/NNG (1.9e+02)\n보/VV (1.5e+02)\n좋/VA (80.8)\n하/VV (51.2)\n음악/NNG (50.8)\n영화/NNP (50.3)\n것/NNB (44.6)\n꿈/NNG (42.5)\n같/VA (40.7)\n있/VV (40.6)\n없/VA (35.5)\n마지막/NNG (33.7)\n아름답/VA (32.1)\n사랑/NNG (30.4)\n수/NNB (29.5)\n현실/NNG (27.9)\n노래/NNG (26.1)\n최고/NNG (23.8)\n스토리/NNP (23.6)\n생각/NNG (23.5)\n되/VV (23.1)\n번/NNB (22.7)\n여운/NNP (22.1)\n감동/NNG (19.1)\n사람/NNG (18.6)\n때/NNG (18.0)\n거/NNB (18.0)\n지루/XR (17.6)\n영상미/NNG (16.8)\n재밌/VA (16.3)\n"
     ]
    }
   ],
   "source": [
    "keyword_extractor = KeywordSummarizer(\n",
    "    tokenize = komoran_tokenize,\n",
    "    window = 2,\n",
    "    verbose = False\n",
    ")\n",
    "keywords = keyword_extractor.summarize(sents, topk=30)\n",
    "for word, rank in keywords:\n",
    "    print('{} ({:.3})'.format(word, rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "핵심 문장을 선택하기 위하여 문장 간 유사도를 계산한 다음, `min_sim` 이상의 유사도를 지니는 문장 간에 adjacent sentence graph 를 만듭니다. 그리고 여기에 PageRank 를 적용하여 핵심 문장을 선택합니다.\n",
    "\n",
    "텍스트를 출력할 때에는 토크나이징된 문장은 가독이 어렵기 때문에 원 텍스트를 이용하여 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calculating textrank sentence similarity was done with 15595 sents\n",
      "trained TextRank. n sentences = 15595\n",
      "#5861 (6.12) : 사랑에 대해 다시 한 번 생각해 볼 수 있게 하는 영화인 것 같습니다 장면 처리도 좋았어요 여운이 많이 남는 영화입니다 꼭 보세요\n",
      "\n",
      "#5947 (5.8) : 아 진짜 평점 처음 써본다 진짜 후회 안할 영화 나중에 다시 봐도 좋을것 같다 오프닝에서 신나는 노래부터 마지막의 상상 하는 씬까지 너무 좋음 결말이 여운이 있다고 해야하나 슬프다고 해야하나 꿈얘기 할때 현실성 있어서 눈물날뻔 결말이짱\n",
      "\n",
      "#5076 (5.69) : 옛날 영화같은 느낌의 기법 사람을 행복하게 만드는 음악 약간의 촌스러움이 마음을 간지를 수 있는 지극히 현실적인 사랑과 꿈이야기를 로맨틱하게 풀어낸 영화로 연말 영화로 보기 좋은 것 같아요\n",
      "\n",
      "#6665 (5.41) : 인생영화다 노래도 너무 좋고 배우 소품 배경 장면들 하나하나 맘에 안 드는게 없다 ㅠㅠ 특히 마지막 셉oo에서의 내용은 진짜 잊을 수가 없을 거같다 보고나면 먹먹하고 안타까운 느낌이 드는데 그래도 황홀하고 아름다운 영화다\n",
      "\n",
      "#9271 (5.28) : 연출 음악 영상미 엔딩은 정말 좋았다 마지막에 남녀주인공이 나눈 눈빛이 아직도 잊혀지지않을만큼 여운이 남는 영화였다 초중반 약간 지루하긴했었다 배우들 춤연습을 많이한게보였음 꿈 성공 과 사랑을 다 가질수 없다는것을 현실적으로보여준 영화가아니었나싶다\n",
      "\n",
      "#13909 (5.12) : 인생 최고의 영화 또보고싶다 영상미 음악 스토리 다 좋아요\n",
      "\n",
      "#5922 (4.99) : 정말 영상미랑 음악은 최고였다 그리고 신선했다 음악이 너무 멋있어서 연기를 봐야 할지 노래를 들어야 할지 모를 정도로 그리고 보고 나서 생각 좀 많아진 영화 정말 이 연말에 보기 좋은 영화 인 것 같다\n",
      "\n",
      "#11408 (4.88) : 진짜 그냥 좋았던 영화 두번봐도 재밌을영화\n",
      "\n",
      "#12362 (4.88) : 보고 난 후 그냥 인생영화 다 라는 말밖에 안나오는 영화다 너무나도 아름다운 색감과 영상미 우리가 꿈꾸는 판타지 로맨스를 그대로 옮겨놓은 듯 하다 영화관을 나와도 귀에 맴도는 음악을 들으며 하늘에 있는 별들을 바라보며 집으로 올수밖에 없었다\n",
      "\n",
      "#187 (4.88) : 저가 본 영화중에서 두번째로 최고인 영화였던것같습니다 노래도너무좋았고 정말 한 장면도 놓칠수없었습니다 재밌었고 앞으로도 이런 비슷한 영화들이나와도 괜찮을것같다 싶었던것같습니다\n",
      "\n",
      "#2082 (4.84) : 뮤지컬영화 처음봐서 처음엔 이게 뭐지 싶었는데 노래가 영화를 얼마나 풍성하게 할 수 있는지 몸소 느꼈다 꿈을 향한 두 남녀의 여정과 사랑이 너무 아름다웠다 참 여운이 남는 영화\n",
      "\n",
      "#14711 (4.84) : 제 인생 최고의 뮤지컬 영화라고 자신있게 말할수 있어요 ㅜ ㅜ 또 보러 갈 예정 음악도 전부 좋고 엔딩크래딧 다 올라갈때까지 자리에서 여윤 때문에 못일어났네요 정말 아름다운 영화였어요 여운이 기네요\n",
      "\n",
      "#980 (4.77) : 좋은 영화다여운이 남고 마지막 장면은 눈물을 참을 수가 없었다 슬픈 눈물이 아닌 아름다운 것을 봤을 때 흘리는 눈물이런 기분이구나\n",
      "\n",
      "#5220 (4.72) : 음악 미술 연기 등 모든 것이 좋았지만 마지막 결말이 너무 현실에 뒤떨어진 꿈만 같다 꿈을 이야기하는 영화지만 과정과 결과에 있어 예술가들의 현실을 너무 반영하지 못한 것이 아닌가하는 생각이든다 그래서 보고 난 뒤 나는 꿈을 꿔야하는데 허탈했다\n",
      "\n",
      "#3099 (4.72) : 세 번째 관람 음악도 좋고 색감도 너무 이뻐요꿈에 대해 생각해 보게 하는 영화\n",
      "\n",
      "#8087 (4.7) : 조금 이해못했었는데 해석을 보니까 다 이해가 되더라고요 꿈과 사랑에 대해서 잘 표현한것 같았어요 이해하니까 여운이 많이 남았어요 노래도 되게 좋았고요 연기도 최고 2016년 말을 장식하는 최고의 영화에요 굿굿\n",
      "\n",
      "#7461 (4.69) : 인생영화가 아니라 인생 최악의 영화 영상미는 좋았지만 싸우는 장면 빼곤 지루하기 짝이 없음 결말도 너무나 어이없었음 평점 후기 보고 기대했는데 어떻게 내 생각과 이렇게 반대일 수 있는지 시간 돈이 아까웠다\n",
      "\n",
      "#10282 (4.63) : 여운 많이 남는 최고의 영화 영상미도 너무 아름답고 보는 내내 가슴이 벅차올랐다 재즈 음악이 많이 들리던 것도 너무 좋다 또 보러갈 예정\n",
      "\n",
      "#583 (4.61) : 눈이 호강하네요 음악도 좋구요 그러나 위플래쉬때와 같이 보고 나면 마음속에 남는것이 하나도 없습니다 음악영화이나 너무 보여주기식으로만 영화를 만드는것이 이 감독의 특징인 것 같습니다\n",
      "\n",
      "#9175 (4.6) : 너무 좋은 영화에요 꼭 보세요\n",
      "\n",
      "#11283 (4.6) : 아주 좋은 영화를 봤습니다\n",
      "\n",
      "#1929 (4.6) : 두고두고 계속 볼 영화 너무나 좋았습니다\n",
      "\n",
      "#2165 (4.6) : 너무 좋았어요 다시 보고싶은 영화에요\n",
      "\n",
      "#6068 (4.6) : 그냥 너랑 봐서 좋았던 영화\n",
      "\n",
      "#11603 (4.6) : 좋은 영화였습니다 또보고싶어요\n",
      "\n",
      "#1242 (4.6) : 정말 좋은 영화였어요 꼭 보세요\n",
      "\n",
      "#3869 (4.59) : 정말 너무 영화 잘 봤습니다 근래들어 본 영화중에 제일 감동 음악도 너무 좋고 배우들도 너무 멋있습니다 마지막 둘의 눈빛 잊을 수가 없네요\n",
      "\n",
      "#7059 (4.57) : 사실 두번째 보는 영화입니다 영상 편집과 음악이 너무 좋아요 어떻게 보면 너무나 현실적일 수 있는 결말이 슬프기하지만 아름답습니다\n",
      "\n",
      "#4033 (4.57) : 다른 분들에 비해 저는 조금 지루하긴 했는데 영상미는 끝내주는 것 같아요 음악도 영화 볼 때보다 보고나서 티비나 거리에서 들려오면 영화생각 나면서 더 좋은 듯\n",
      "\n",
      "#4357 (4.56) : 세번 봤어요 이동진 평론가 평 보고 다시 보니까 처음 봤을 때 말로 표현할 수 없던 감정들이 정리가 되는 느낌이어서 더 좋았어요 사랑영화이기도 하면서 성장영화이기도 한 라라랜드 인생영화에요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textrank import KeysentenceSummarizer\n",
    "\n",
    "summarizer = KeysentenceSummarizer(\n",
    "    tokenize = komoran_tokenize,\n",
    "    min_sim = 0.5,\n",
    "    verbose = True\n",
    ")\n",
    "keysents = summarizer.summarize(sents)\n",
    "for idx, rank, komoran_sent in keysents:\n",
    "    print('#{} ({:.3}) : {}'.format(idx, rank, texts[idx]), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 뉴스 기사에 대하여 3 개의 핵심 문장을 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\n",
    "'도로에서 60대 택시기사의 얼굴을 수차례에 걸쳐 폭행해 공분을 일으킨 20대 남성이 구속됐다.', '7일 오후 서울중앙지법 서보민 영장전담 부장판사는 상해 및 공무집행방해 혐의를 받는 20대 A씨의 구속영장을 발부했다.', '서 부장판사는 “피의자가 피의사실과 같은 죄를 범하였다고 의심할 만한 상당한 이유가 있고 도망할 염려가 있어 구속의 사유와 필요성이 인정된다”고 밝혔다.', 'A씨는 앞서 지난 5일 오후 10시쯤 서울 관악구 신림동 난곡터널 인근에서 60대 택시기사 B씨를 도로에 넘어뜨리고 얼굴을 수차례 때려 상해를 입힌 혐의를 받고 있다.', '특히 A씨의 폭행 영상은 한 온라인 커뮤니티에 공유되면서 논란이 됐다. 가해자 엄벌을 촉구하는 청와대 국민청원도 올라와 하루 만에 2200명 이상의 동의를 받았다.', 'B씨는 현재 치아가 깨지고 머리 쪽을 크게 다쳐 수술이 필요할 정도의 상태인 것으로 전해졌다.', '경찰은 B씨의 상태가 호전되면 소환 조사를 진행할 방침이다.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "띄어쓰기 기준으로 adjacent sentence graph 를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\"신선 농산물과 양념 재료가 모두 들어있어 집에서 간편하게 음식을 만들어 먹을 수 있는 '밀키트' 제품이 인기를 끌고 있습니다.\", '코로나19로 수요가 더 늘어나고 있는데요,', '지역 농산물로 제품을 만들다 보니 주변 농가들에도 큰 도움이 되고 있습니다.', '오종우 기자의 보도입니다.', \"'소고기 야채전골'을 해먹을 수 있는 재료와 양념이 모두 들어있는 이른바, 밀키트 제품입니다.\", '외식보다 저렴한 비용에 버섯과 청경채 같은 신선 농산물이 든 건강식을 먹을 수 있어 인기입니다.', '밀양의 이 제조업체는 상품 출시 1년 만에 50억 원의 매출을 기록했습니다.', '코로나19로 집밥 수요가 크게 늘어난 덕분입니다.', '[엄성민/밀양 밀키트 제조업체 : 저희가 손질이나 세척과정 없이 농산물 그대로를 사용하기 때문에 소비자분들이 원물의 신선도를 눈으로 확인하시고 섭취가 가능하십니다.] 밀양지역 농가들과 올해 맺은 계약재배 금액만 24억 원 수확량의 절반가량은 계약재배를 한 덕분에 농민들은 가격 등락에 관계없이 농사에만 전념할 수 있습니다.', '[최광호/밀양 서홍감자 작목반 회장 : 1kg당 2천 원씩 계약을 해서, 일반 농가보다 한 동에, 하우스 한 동에 한 150만 원 정도 돈을 더 받았습니다. 밀키트에 들어가는 양배추와 상추, 깻잎 등 70여 가지 농산물을 밀양지역 농가에서 구매해 농민들 입장에선 든든한 거래처가 생긴 겁니다. [곽선칠/친환경농업인연합회 밀양시지부 회장 : 타지의 상인들보다도 지역 업체로서 아무래도 농민을 많이 생각하는 쪽에 서지 않나 생각합니다.', '코로나19 여파로 인기를 끌고 있는 밀키트 제품이 어려움을 겪고 있는 주변 농가들에게 효자 노릇을 톡톡히 하고 있습니다.', 'KBS 뉴스 오종우입니다.']\n"
     ]
    }
   ],
   "source": [
    "import kss\n",
    "s = \"신선 농산물과 양념 재료가 모두 들어있어 집에서 간편하게 음식을 만들어 먹을 수 있는 '밀키트' 제품이 인기를 끌고 있습니다.코로나19로 수요가 더 늘어나고 있는데요,지역 농산물로 제품을 만들다 보니 주변 농가들에도 큰 도움이 되고 있습니다. 오종우 기자의 보도입니다. '소고기 야채전골'을 해먹을 수 있는 재료와 양념이 모두 들어있는 이른바, 밀키트 제품입니다. 외식보다 저렴한 비용에 버섯과 청경채 같은 신선 농산물이 든 건강식을 먹을 수 있어 인기입니다. 밀양의 이 제조업체는 상품 출시 1년 만에 50억 원의 매출을 기록했습니다. 코로나19로 집밥 수요가 크게 늘어난 덕분입니다. [엄성민/밀양 밀키트 제조업체 : 저희가 손질이나 세척과정 없이 농산물 그대로를 사용하기 때문에 소비자분들이 원물의 신선도를 눈으로 확인하시고 섭취가 가능하십니다.] 밀양지역 농가들과 올해 맺은 계약재배 금액만 24억 원! 수확량의 절반가량은 계약재배를 한 덕분에 농민들은 가격 등락에 관계없이 농사에만 전념할 수 있습니다. [최광호/밀양 서홍감자 작목반 회장 : 1kg당 2천 원씩 계약을 해서, 일반 농가보다 한 동에, 하우스 한 동에 한 150만 원 정도 돈을 더 받았습니다. 밀키트에 들어가는 양배추와 상추, 깻잎 등 70여 가지 농산물을 밀양지역 농가에서 구매해 농민들 입장에선 든든한 거래처가 생긴 겁니다. [곽선칠/친환경농업인연합회 밀양시지부 회장 : 타지의 상인들보다도 지역 업체로서 아무래도 농민을 많이 생각하는 쪽에 서지 않나 생각합니다. 코로나19 여파로 인기를 끌고 있는 밀키트 제품이 어려움을 겪고 있는 주변 농가들에게 효자 노릇을 톡톡히 하고 있습니다. KBS 뉴스 오종우입니다.\"\n",
    "characters = '\"!?\\n'\n",
    "\n",
    "for x in range(len(characters)):\n",
    "    s = s.replace(characters[x],\"\")\n",
    "\n",
    "sts = []\n",
    "for sent in kss.split_sentences(s):\n",
    "    sts.append(sent)\n",
    "print(sts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "신선 농산물과 양념 재료가 모두 들어있어 집에서 간편하게 음식을 만들어 먹을 수 있는 '밀키트' 제품이 인기를 끌고 있습니다.\n[엄성민/밀양 밀키트 제조업체 : 저희가 손질이나 세척과정 없이 농산물 그대로를 사용하기 때문에 소비자분들이 원물의 신선도를 눈으로 확인하시고 섭취가 가능하십니다.] 밀양지역 농가들과 올해 맺은 계약재배 금액만 24억 원! 수확량의 절반가량은 계약재배를 한 덕분에 농민들은 가격 등락에 관계없이 농사에만 전념할 수 있습니다.\n코로나19 여파로 인기를 끌고 있는 밀키트 제품이 어려움을 겪고 있는 주변 농가들에게 효자 노릇을 톡톡히 하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sents = \"신선 농산물과 양념 재료가 모두 들어있어 집에서 간편하게 음식을 만들어 먹을 수 있는 '밀키트' 제품이 인기를 끌고 있습니다.코로나19로 수요가 더 늘어나고 있는데요,지역 농산물로 제품을 만들다 보니 주변 농가들에도 큰 도움이 되고 있습니다. 오종우 기자의 보도입니다. '소고기 야채전골'을 해먹을 수 있는 재료와 양념이 모두 들어있는 이른바, 밀키트 제품입니다. 외식보다 저렴한 비용에 버섯과 청경채 같은 신선 농산물이 든 건강식을 먹을 수 있어 인기입니다. 밀양의 이 제조업체는 상품 출시 1년 만에 50억 원의 매출을 기록했습니다. 코로나19로 집밥 수요가 크게 늘어난 덕분입니다. 엄성민/밀양 밀키트 제조업체 : 저희가 손질이나 세척과정 없이 농산물 그대로를 사용하기 때문에 소비자분들이 원물의 신선도를 눈으로 확인하시고 섭취가 가능하십니다. 밀양지역 농가들과 올해 맺은 계약재배 금액만 24억 원! 수확량의 절반가량은 계약재배를 한 덕분에 농민들은 가격 등락에 관계없이 농사에만 전념할 수 있습니다. 최광호/밀양 서홍감자 작목반 회장 : 1kg당 2천 원씩 계약을 해서, 일반 농가보다 한 동에, 하우스 한 동에 한 150만 원 정도 돈을 더 받았습니다. 밀키트에 들어가는 양배추와 상추, 깻잎 등 70여 가지 농산물을 밀양지역 농가에서 구매해 농민들 입장에선 든든한 거래처가 생긴 겁니다. 곽선칠/친환경농업인연합회 밀양시지부 회장 : 타지의 상인들보다도 지역 업체로서 아무래도 농민을 많이 생각하는 쪽에 서지 않나 생각합니다. 코로나19 여파로 인기를 끌고 있는 밀키트 제품이 어려움을 겪고 있는 주변 농가들에게 효자 노릇을 톡톡히 하고 있습니다. KBS 뉴스 오종우입니다.\"\n",
    "\n",
    "sts = []\n",
    "for sent in kss.split_sentences(sents):\n",
    "    sts.append(sent)\n",
    "\n",
    "summarizer = KeysentenceSummarizer(\n",
    "    tokenize = lambda x:x.split(),\n",
    "    min_sim = 0.3,\n",
    "    verbose = False\n",
    ")\n",
    "keysents = summarizer.summarize(sts, topk=3)\n",
    "for _, _, sent in keysents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['도로에서 60대 택시기사의 얼굴을 수차례에 걸쳐 폭행해 공분을 일으킨 20대 남성이 구속됐다.',\n",
       " '7일 오후 서울중앙지법 서보민 영장전담 부장판사는 상해 및 공무집행방해 혐의를 받는 20대 A씨의 구속영장을 발부했다.',\n",
       " '서 부장판사는 “피의자가 피의사실과 같은 죄를 범하였다고 의심할 만한 상당한 이유가 있고 도망할 염려가 있어 구속의 사유와 필요성이 인정된다”고 밝혔다.',\n",
       " 'A씨는 앞서 지난 5일 오후 10시쯤 서울 관악구 신림동 난곡터널 인근에서 60대 택시기사 B씨를 도로에 넘어뜨리고 얼굴을 수차례 때려 상해를 입힌 혐의를 받고 있다.',\n",
       " '특히 A씨의 폭행 영상은 한 온라인 커뮤니티에 공유되면서 논란이 됐다. 가해자 엄벌을 촉구하는 청와대 국민청원도 올라와 하루 만에 2200명 이상의 동의를 받았다.',\n",
       " 'B씨는 현재 치아가 깨지고 머리 쪽을 크게 다쳐 수술이 필요할 정도의 상태인 것으로 전해졌다.',\n",
       " '경찰은 B씨의 상태가 호전되면 소환 조사를 진행할 방침이다.']"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (gru_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-37998ce95f70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpykospacing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSpacing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pykospacing\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpykospacing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkospacing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pykospacing\\kospacing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m dic_path = pkg_resources.resource_filename(\n\u001b[0;32m     16\u001b[0m     'pykospacing', os.path.join('resources', 'dicts', 'c2v.dic'))\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mMODEL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mW2IDX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdic_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    199\u001b[0m         if (h5py is not None and\n\u001b[0;32m    200\u001b[0m             (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m--> 201\u001b[1;33m           return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n\u001b[0m\u001b[0;32m    202\u001b[0m                                                   compile)\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    178\u001b[0m       \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m     model = model_config_lib.model_from_config(model_config,\n\u001b[0m\u001b[0;32m    181\u001b[0m                                                custom_objects=custom_objects)\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\saving\\model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     57\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[0;32m     58\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    157\u001b[0m   \"\"\"\n\u001b[0;32m    158\u001b[0m   \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m   return generic_utils.deserialize_keras_object(\n\u001b[0m\u001b[0;32m    160\u001b[0m       \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m'custom_objects'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         deserialized_obj = cls.from_config(\n\u001b[0m\u001b[0;32m    669\u001b[0m             \u001b[0mcls_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m             custom_objects=dict(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m   2355\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSharedObjectLoadingScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2356\u001b[0m       input_tensors, output_tensors, created_layers = (\n\u001b[1;32m-> 2357\u001b[1;33m           functional.reconstruct_from_config(config, custom_objects))\n\u001b[0m\u001b[0;32m   2358\u001b[0m       \u001b[1;31m# Initialize a model belonging to `cls`, which can be user-defined or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m       \u001b[1;31m# `Functional`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mreconstruct_from_config\u001b[1;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[0;32m   1287\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnode_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1289\u001b[1;33m           \u001b[0mprocess_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m   \u001b[0minput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mprocess_node\u001b[1;34m(layer, node_data)\u001b[0m\n\u001b[0;32m   1235\u001b[0m         input_tensors = (\n\u001b[0;32m   1236\u001b[0m             base_layer_utils.unnest_if_single_tensor(input_tensors))\n\u001b[1;32m-> 1237\u001b[1;33m       \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m       \u001b[1;31m# Update node index map.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    970\u001b[0m                                                 input_list)\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1106\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1108\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;31m# GRU does not support constants. Ignore it during process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m       \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m       init_state = get_initial_state_fn(\n\u001b[0m\u001b[0;32m    651\u001b[0m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001b[0;32m    652\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state_for_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[1;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2996\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2997\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2998\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state\u001b[1;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[0;32m   3014\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_zeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3015\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3016\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcreate_zeros\u001b[1;34m(unnested_state_size)\u001b[0m\n\u001b[0;32m   3009\u001b[0m     \u001b[0mflat_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munnested_state_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3010\u001b[0m     \u001b[0minit_state_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size_tensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflat_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3011\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3013\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2910\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2911\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2912\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2913\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2958\u001b[0m           \u001b[1;31m# Create a constant if it won't be very big. Otherwise create a fill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2959\u001b[0m           \u001b[1;31m# op to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2960\u001b[1;33m           \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2961\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   2894\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2895\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2896\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2897\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   3028\u001b[0m         \u001b[0mbut\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresulting\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcast\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnecessary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m     \u001b[0mReturns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m     \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m     \u001b[0mcumprod\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m     raise NotImplementedError(\n\u001b[0m\u001b[0;32m    868\u001b[0m         \u001b[1;34m\"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;34m\" This error may indicate that you're trying to pass a Tensor to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (gru_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": [
    "from pykospacing import Spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = '김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.'\n",
    "new_sent = sent.replace(\" \", '') # 띄어쓰기가 없는 문장 임의로 만들기\n",
    "print(new_sent)\n",
    "\n",
    "kospacing_sent = Spacing(new_sent)\n",
    "print(sent)\n",
    "print(kospacing_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "신선 농산물과 양념 재료가 모두 들어있어 집에서 간편하게 음식을 만들어 먹을 수 있는 '밀키트' 제품이 인기를 끌고 있습니다.\n[엄성민/밀양 밀키트 제조업체 : 저희가 손질이나 세척과정 없이 농산물 그대로를 사용하기 때문에 소비자분들이 원물의 신선도를 눈으로 확인하시고 섭취가 가능하십니다.] 밀양지역 농가들과 올해 맺은 계약재배 금액만 24억 원! 수확량의 절반가량은 계약재배를 한 덕분에 농민들은 가격 등락에 관계없이 농사에만 전념할 수 있습니다.\n코로나19 여파로 인기를 끌고 있는 밀키트 제품이 어려움을 겪고 있는 주변 농가들에게 효자 노릇을 톡톡히 하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from textrank import KeysentenceSummarizer\n",
    "\n",
    "summarizer = KeysentenceSummarizer(\n",
    "    tokenize = lambda x:x.split(),\n",
    "    min_sim = 0.3,\n",
    "    verbose = False\n",
    ")\n",
    "keysents = summarizer.summarize(sts, topk=3)\n",
    "for _, _, sent in keysents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'7일 오후 서울중앙지법 서보민 영장전담 부장판사는 상해 및 공무집행방해 혐의를 받는 20대 A씨의 구속영장을 발부했다.'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "sents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KoNLPy 의 Komoran 을 이용하여 토크나이징과 핵심문장을 한 번에 추출하는 예시입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _jpype: DLL 초기화 루틴을 실행할 수 없습니다.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a8b33b4bcece>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKomoran\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkomoran\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKomoran\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mkomoran_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkomoran\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\konlpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minit_jvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m from konlpy import (\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\konlpy\\tag\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hannanum\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHannanum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kkma\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKkma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_komoran\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKomoran\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\konlpy\\tag\\_hannanum.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mjpype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjvm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\jpype\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# *****************************************************************************\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0m_jpype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_jinit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_jpackage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _jpype: DLL 초기화 루틴을 실행할 수 없습니다."
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran()\n",
    "def komoran_tokenizer(sent):\n",
    "    words = komoran.pos(sent, join=True)\n",
    "    words = [w for w in words if ('/NN' in w or '/XR' in w or '/VA' in w or '/VV' in w)]\n",
    "    return words\n",
    "\n",
    "summarizer = KeysentenceSummarizer(\n",
    "    tokenize = komoran_tokenizer,\n",
    "    min_sim = 0.3,\n",
    "    verbose = False\n",
    ")\n",
    "keysents = summarizer.summarize(sents, topk=3)\n",
    "for _, _, sent in keysents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실 위의 결과를 얻기 위해서는 토크나이저도 제대로 구축할 필요가 없습니다. 어자피 많이 등장한 단어라면 해당 단어를 구성하는 부분어절 (subword) 역시 자주 등장하였을 것이며, 이를 이용한 문장 간 유사도를 측정하여도 비슷하기 때문입니다.\n",
    "\n",
    "아래는 띄어쓰기 기준으로 나뉘어진 어절에서 3음절의 subwords 를 잘라내는 토크나이저 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이것은',\n",
       " '부분단',\n",
       " '분단어',\n",
       " '단어의',\n",
       " '예시입',\n",
       " '시입니',\n",
       " '입니다',\n",
       " '짧은',\n",
       " '어절은',\n",
       " '그대로',\n",
       " '나옵니',\n",
       " '옵니다']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def subword_tokenizer(sent, n=3):\n",
    "    def subword(token, n):\n",
    "        if len(token) <= n:\n",
    "            return [token]\n",
    "        return [token[i:i+n] for i in range(len(token) - n + 1)]\n",
    "    return [sub for token in sent.split() for sub in subword(token, n)]\n",
    "\n",
    "subword_tokenizer('이것은 부분단어의 예시입니다 짧은 어절은 그대로 나옵니다')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 이용하여도 핵심 문장은 위와 동일하게 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다\n",
      "용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기\n",
      "총격현장 수색하는 경찰들 서울 연합뉴스 이효석 기자 19일 오후 서울 강북구 오패산 터널 인근에서 경찰들이 폭행 용의자가 사제총기를 발사해 경찰관이 사망한 사건을 조사 하고 있다\n"
     ]
    }
   ],
   "source": [
    "summarizer = KeysentenceSummarizer(\n",
    "    tokenize = subword_tokenizer,\n",
    "    min_sim = 0.3,\n",
    "    verbose = False\n",
    ")\n",
    "keysents = summarizer.summarize(sents, topk=3)\n",
    "for _, _, sent in keysents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summarizer 의 R 에는 각 문장 별 중요도 (PageRank 값) 가 저장되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.76438621, 0.74969733, 1.33782296, 0.61722741, 0.7377122 ,\n",
       "       1.07534516, 0.62928904, 1.71145208, 1.07601036, 1.13590053,\n",
       "       0.94446938, 0.67686714, 0.7008805 , 1.02103025, 1.61461996,\n",
       "       0.76911158, 0.78024047, 0.65793743, 1.02927478, 0.97072522])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장의 위치에 따라 중요도를 다르게 설정할 수도 있습니다. 뉴스 기사는 대부분 첫 문장이 중요합니다. 실제로 위의 예시에서도 첫 문장이 가장 중요한 핵심 문장으로 선택되었습니다. 만약 마지막 문장이 중요하다고 가정한다면 이러한 정보를 bias 에 추가할 수 있습니다. numpy.ndarray 형태로 bias 를 만듭니다. 마지막 문장이 다른 문장보다 10 배 중요하다고 가정하였습니다. 이를 summarize 함수의 bias 에 입력하면 가장 먼저 맨 마지막 문장이 중요한 문장으로 선택됩니다. 다른 문장들 중에서도 맨 마지막 문장과 비슷할수록 상대적인 중요도가 더 커집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일부는 숲에서 발견됐고 일부는 성씨가 소지한 가방 안에 있었다\n",
      "경찰은 인근을 수색해 성씨가 만든 사제총 16정과 칼 7개를 압수했다 실제 폭발할지는 알 수 없는 요구르트병에 무언가를 채워두고 심지를 꽂은 사제 폭탄도 발견됐다\n",
      "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bias = np.ones(len(sents))\n",
    "bias[-1] = 10\n",
    "\n",
    "keysents = summarizer.summarize(sents, topk=3, bias=bias)\n",
    "for _, _, sent in keysents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R 을 다시 확인해보면 PageRank 값이 달라졌음을 확인할 수 있습니다. 상대적인 위치 외에도 특정 단어가 포함된 문장에 preference (bias) 를 더 높게 설정할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.22183954, 0.51902092, 0.92584783, 0.42671701, 0.50982682,\n",
       "       0.74430683, 0.43498201, 1.18547126, 0.74505343, 0.78632222,\n",
       "       0.65347844, 0.46802437, 0.48465947, 0.70684359, 1.11845189,\n",
       "       0.53125081, 0.53956034, 0.45476333, 3.14941282, 4.39416707])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python390jvsc74a57bd0473a43ed9ce3452be6d1c70e7aecf51cbc9f343b67659ff8658c67a5e80331e8",
   "display_name": "Python 3.9.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}